{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Python and _pandas_, read two Excel worksheets, merge the data, and make the data available for analysis.\n",
    "\n",
    "- Final data should be exported to Excel format, and should be easy to download.\n",
    "- Results must be reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare, we need to be able to open the Excel files, display results of intermediate processing in the notebook, and avoid repeating large blocks of code.\n",
    "\n",
    "Some functions can be imported, as they're already available publicly. Others will be made here, in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The display function isn't always imported by default in some Jupyter implementations.\n",
    "# We'll probably use it a lot.\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter can output HTML if we want. Here are simple helpers to make headings\n",
    "and other embellishments easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_wrap(content, element=\"span\", attributes=None):\n",
    "    \"\"\" Convenience method for wrapping any string in an HTML tag. \"\"\"\n",
    "    element_with_attributes = ' '.join((item for item in (element, attributes) if not item is None))\n",
    "    tag_open = f\"<{element_with_attributes}>\"\n",
    "    tag_close = f\"</{element}>\"\n",
    "    return f\"{tag_open}{content}{tag_close}\"\n",
    "\n",
    "\n",
    "def make_heading(content, level=5):\n",
    "    \"\"\" Convenience method for wrapping any string in an HTML header tag. \"\"\"\n",
    "    element = f\"h{level}\"\n",
    "    return html_wrap(content, element)\n",
    "\n",
    "\n",
    "def heading(*args, **kwargs):\n",
    "    \"\"\" Call IPython.core.display.HTML on the results of the make_heading function,\n",
    "    so users don't have to repeatedly do `HTML(heading(…))` \"\"\"\n",
    "    return HTML(make_heading(*args, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[_pandas_] is really good with columnar data, like Excel files:\n",
    "\n",
    "[_pandas_]: https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Excel workbook: `2017 CAM data from iPads.xlxs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file I'm interested in parsing for cleanup:\n",
    "file_path = \"./src/real data/2017 CAM data from iPads/2017 CAM data from iPads.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017 CAM data Erl',\n",
       " '2017 CAM iPad data Tyler',\n",
       " 'Combined iPad 2017 CAM data',\n",
       " 'schema (WIP reverse engineer)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = pandas.ExcelFile(file_path)\n",
    "sorted(data_file.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm only interested in first two, for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_sheet_names = _[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dictionary of dataframes from all the sheets, using the last word as the name. In Python, an index of -1 means the last item, as in, one less than the largest index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_word(string, word_separator=' '):\n",
    "    return string.split(' ')[-1]\n",
    "\n",
    "\n",
    "sheets = {last_word(sheet_name): data_file.parse(sheet_name)\n",
    "          for sheet_name in cam_sheet_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Erl', 'Tyler'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The keys are sheet names. Let's see what we've got:\n",
    "sheets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a convenient list of sheets that are loaded as _pandas_ DataFrames, we can work toward merging them into one. Once they're merged, we can process the data more easily from a single DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries in Python are just a collection of named things. The things can be another dictionary, a string, a number, or whatver. Even the names of the things don't necessarily have to be words—they can be numbers, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary:\n",
    "my_dictionary = {\n",
    "    'one': 1,\n",
    "    2: 'two',\n",
    "    'green': 'I like colour green.',\n",
    "    'another dictionary': {'more stuff': 1024,\n",
    "                           'even more stuff': 2048},\n",
    "    'a list': [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall something from that dictionary:\n",
    "my_dictionary[\"one\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary[\"another dictionary\"][\"even more stuff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attempt to use a non-existant key results in a Python exception called a `KeyError`. This is helpful if you accidentally lose track of which keys are in the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"some key that doesn't exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6706547ecbde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"some key that doesn't exist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"some key that doesn't exist\""
     ]
    }
   ],
   "source": [
    "my_dictionary[\"some key that doesn't exist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want an this to happen, there are ways to get around it. Later on, we'll use something called a [`defaultdict`], which just makes up the new key on the spot, instead of stopping dead.\n",
    "\n",
    "[`defaultdict`]: https://docs.python.org/3/library/collections.html?highlight=defaultdict#defaultdict-objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `for` with dictionaries in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `for` statements are handy for doing something to each item in a collection. Dictionaries are a type of collection, but since they have keys and values, you need to specify which you want. To address this, there are three handy methods that all dictionaries have:\n",
    "\n",
    "- `keys()` - Only the key names\n",
    "- `values()` - Only the values\n",
    "- `items()` - Pairs of keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'green'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'another dictionary'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'a list'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in my_dictionary.keys():\n",
    "    display(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I like colour green.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'even more stuff': 2048, 'more stuff': 1024}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for value in my_dictionary.values():\n",
    "    display(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('one', 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 'two')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('green', 'I like colour green.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('another dictionary', {'even more stuff': 2048, 'more stuff': 1024})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('a list', [1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in my_dictionary.items():\n",
    "    display(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about lists, dictionaries, and other data structures in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about using dictionaries, see the official [Python tutorial on dictionaries], which is part of the page demonstrating other Python collections, such as [lists], which we'll be using extensively.\n",
    "\n",
    "[Python tutorial on dictionaries]: https://docs.python.org/3/tutorial/datastructures.html#dictionaries\n",
    "[lists]: https://docs.python.org/3/tutorial/datastructures.html#more-on-lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unifying the DataFrames (worksheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _pandas_ functions for merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ has multiple methods for combining datasets:\n",
    "\n",
    "- [`concat`]: The concatenate method has an option to ignore row numbers, which has the effect of gluing each dataframe to the bottom of the previous one.\n",
    "- [`append`]: Append would be almost equivalent, but always updates the first DataFrame or Series it's given.\n",
    "- [`merge`]: Merge is more for database-style relational merges.\n",
    "\n",
    "[`concat`]: https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "[`append`]: https://pandas.pydata.org/pandas-docs/stable/merging.html#concatenating-using-append\n",
    "[`merge`]: https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n",
    "\n",
    "From reading up on all three methods, it looks to me like `concat` will suffice, here, as long as the column names are identical. I like to have the option of creating a new DataFrame rather than overwriting anything, because the results are easier to repeat.\n",
    "\n",
    "Let's see how close that concatenation method gets us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4690 entries, (Erl, 0) to (Tyler, 3779)\n",
      "Data columns (total 56 columns):\n",
      "clients__company                                                    1 non-null object\n",
      "clients__displayText                                                1 non-null object\n",
      "clients__fname                                                      1 non-null object\n",
      "clients__lname                                                      1 non-null object\n",
      "clients__name                                                       1 non-null object\n",
      "fields__client__company                                             21 non-null object\n",
      "fields__client__displayText                                         21 non-null object\n",
      "fields__client__fname                                               21 non-null object\n",
      "fields__client__lname                                               21 non-null object\n",
      "fields__client__name                                                21 non-null object\n",
      "fields__crop                                                        21 non-null object\n",
      "fields__date                                                        21 non-null object\n",
      "fields__desc                                                        15 non-null object\n",
      "fields__image                                                       21 non-null object\n",
      "fields__name                                                        21 non-null object\n",
      "fields__oSets__completeSets                                         54 non-null float64\n",
      "fields__oSets__date                                                 54 non-null object\n",
      "fields__oSets__dateCompare                                          54 non-null datetime64[ns]\n",
      "fields__oSets__desc                                                 0 non-null float64\n",
      "fields__oSets__growthStage                                          45 non-null float64\n",
      "fields__oSets__growthStage Zadoks                                   9 non-null float64\n",
      "fields__oSets__oPoints__id                                          335 non-null float64\n",
      "fields__oSets__oPoints__location__coords__accuracy                  250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__altitude                  250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__altitudeAccuracy          250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__heading                   247 non-null float64\n",
      "fields__oSets__oPoints__location__coords__latitude                  250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__longitude                 250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__speed                     250 non-null float64\n",
      "fields__oSets__oPoints__location__timestamp                         250 non-null float64\n",
      "fields__oSets__oPoints__name                                        335 non-null object\n",
      "fields__oSets__oPoints__observations__a1__number                    324 non-null float64\n",
      "fields__oSets__oPoints__observations__a1__number EGA                124 non-null float64\n",
      "fields__oSets__oPoints__observations__a2__number                    112 non-null float64\n",
      "fields__oSets__oPoints__observations__a2__number BCO                30 non-null float64\n",
      "fields__oSets__oPoints__observations__a3__number                    25 non-null float64\n",
      "fields__oSets__oPoints__observations__a3__number Greenbug           0 non-null float64\n",
      "fields__oSets__oPoints__observations__anum                          1350 non-null float64\n",
      "fields__oSets__oPoints__observations__anum TotalAPhids              325 non-null float64\n",
      "fields__oSets__oPoints__observations__complete                      1937 non-null float64\n",
      "fields__oSets__oPoints__observations__disabled                      0 non-null float64\n",
      "fields__oSets__oPoints__observations__eVnum                         270 non-null float64\n",
      "fields__oSets__oPoints__observations__eVnum Natural enemy totals    65 non-null float64\n",
      "fields__oSets__oPoints__observations__enum                          335 non-null float64\n",
      "fields__oSets__oPoints__observations__id                            2010 non-null float64\n",
      "fields__oSets__oPoints__observations__name                          2010 non-null object\n",
      "fields__oSets__oPoints__observations__|                             3015 non-null object\n",
      "fields__oSets__oPoints__observations__|__number                     172 non-null float64\n",
      "fields__oSets__obsName                                              54 non-null object\n",
      "fields__oSets__results                                              52 non-null object\n",
      "fields__oSets__totalA1                                              52 non-null float64\n",
      "fields__oSets__totalA2                                              52 non-null float64\n",
      "fields__oSets__totalA3                                              52 non-null float64\n",
      "fields__oSets__totalA4                                              52 non-null float64\n",
      "fields__oSets__totalSets                                            54 non-null float64\n",
      "observers                                                           3 non-null object\n",
      "dtypes: datetime64[ns](1), float64(33), object(22)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "pandas.concat(sheets).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the RangeIndex size in the info: \n",
    "\n",
    ">MultiIndex: 4690 entries, (Erl, 0) to (Tyler, 3779)\n",
    "\n",
    "Which means 4690 \"rows\", if this were a spreadsheet. Compare to the total row count for all sheets, by using Python's function `len` (an abbreviation for \"length\"), which counts the number of items (in this case, rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(sheet) for sheet in sheets.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in the `info()` readout:\n",
    "\n",
    ">Data columns (total 56 columns):\n",
    "\n",
    "Compare to the column count for the source worksheets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 50]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sheet.columns) for sheet in sheets.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 50 columns in each source sheet.\n",
    "\n",
    "Pretty good, so far, except for some extra columns due to variations in the column names—I see `growthStage` and `growthStage Zadoks`, as well as some aphid names amongst the `a1__number`, `a2__number`, `a3__number` group:\n",
    "\n",
    "```\n",
    "fields__oSets__growthStage                                  45 non-null float64\n",
    "fields__oSets__growthStage Zadoks                           9 non-null float64\n",
    "```\n",
    "\n",
    "```\n",
    "fields__oSets__oPoints__observations__a1__number            324 non-null float64\n",
    "fields__oSets__oPoints__observations__a1__number EGA        124 non-null float64\n",
    "fields__oSets__oPoints__observations__a2__number            112 non-null float64\n",
    "fields__oSets__oPoints__observations__a2__number BCO        30 non-null float64\n",
    "fields__oSets__oPoints__observations__a3__number            25 non-null float64\n",
    "fields__oSets__oPoints__observations__a3__number Greenbug   0 non-null float64\n",
    "```\n",
    "\n",
    "The total number of rows is correct, and the other columns line up when the names match.\n",
    "\n",
    "Column names (which become Series names in _pandas_) are the only problem standing in the way of a successful unification of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column names differ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's already pretty obvious what the naming problem is. But just to demonstrate how to use _pandas_ to calculate differences, let's look again at our DataFrames column names.\n",
    "\n",
    "For our frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Erl', 'Tyler'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference in column names, using \"Erl\" as the base, and Python's set theory models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields__oSets__growthStage Zadoks',\n",
       " 'fields__oSets__oPoints__observations__a1__number EGA',\n",
       " 'fields__oSets__oPoints__observations__a2__number BCO',\n",
       " 'fields__oSets__oPoints__observations__a3__number Greenbug',\n",
       " 'fields__oSets__oPoints__observations__anum TotalAPhids',\n",
       " 'fields__oSets__oPoints__observations__eVnum Natural enemy totals'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(set.difference(*[set(sheet.columns) for sheet in sheets.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if we want to list the names of columns from *all* sheets that don't have a match (symmetric difference):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fields__oSets__growthStage',\n",
       " 'fields__oSets__growthStage Zadoks',\n",
       " 'fields__oSets__oPoints__observations__a1__number',\n",
       " 'fields__oSets__oPoints__observations__a1__number EGA',\n",
       " 'fields__oSets__oPoints__observations__a2__number',\n",
       " 'fields__oSets__oPoints__observations__a2__number BCO',\n",
       " 'fields__oSets__oPoints__observations__a3__number',\n",
       " 'fields__oSets__oPoints__observations__a3__number Greenbug',\n",
       " 'fields__oSets__oPoints__observations__anum',\n",
       " 'fields__oSets__oPoints__observations__anum TotalAPhids',\n",
       " 'fields__oSets__oPoints__observations__eVnum',\n",
       " 'fields__oSets__oPoints__observations__eVnum Natural enemy totals']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_list = sorted(set.symmetric_difference(*[set(sheet.columns) for sheet in sheets.values()]))\n",
    "display(column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pop it into a two column layout for _pandas_ to display. I found a handy list-to-grid [recipe] on the official documentation for Python's `itertools` library. I based my function on their `grouper` example.\n",
    "\n",
    "[recipe]: https://docs.python.org/3/library/itertools.html#itertools-recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(items, width=2):\n",
    "    \"\"\" Layout items in a grid, from left to right, top to bottom. \"\"\"\n",
    "    return [*zip(*[iter(items)] * width)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_grid = pandas.DataFrame(grid(column_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fields__oSets__growthStage</td>\n",
       "      <td>fields__oSets__growthStage Zadoks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fields__oSets__oPoints__observations__a1__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a1__number EGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fields__oSets__oPoints__observations__a2__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a2__number BCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fields__oSets__oPoints__observations__a3__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a3__number Greenbug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fields__oSets__oPoints__observations__anum</td>\n",
       "      <td>fields__oSets__oPoints__observations__anum TotalAPhids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fields__oSets__oPoints__observations__eVnum</td>\n",
       "      <td>fields__oSets__oPoints__observations__eVnum Natural enemy totals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "0  fields__oSets__growthStage                         \n",
       "1  fields__oSets__oPoints__observations__a1__number   \n",
       "2  fields__oSets__oPoints__observations__a2__number   \n",
       "3  fields__oSets__oPoints__observations__a3__number   \n",
       "4  fields__oSets__oPoints__observations__anum         \n",
       "5  fields__oSets__oPoints__observations__eVnum        \n",
       "\n",
       "                                                                  1  \n",
       "0  fields__oSets__growthStage Zadoks                                 \n",
       "1  fields__oSets__oPoints__observations__a1__number EGA              \n",
       "2  fields__oSets__oPoints__observations__a2__number BCO              \n",
       "3  fields__oSets__oPoints__observations__a3__number Greenbug         \n",
       "4  fields__oSets__oPoints__observations__anum TotalAPhids            \n",
       "5  fields__oSets__oPoints__observations__eVnum Natural enemy totals  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display entire column, even if cell data is long\n",
    "pandas.set_option('display.max_colwidth', 0)  # Zero means no limit\n",
    "\n",
    "# Show the differing column names side-by-side\n",
    "display(column_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose the frame by viewing the `T` attribute of our DataFrame, so differences are vertically adjacent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fields__oSets__growthStage</td>\n",
       "      <td>fields__oSets__oPoints__observations__a1__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a2__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a3__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__anum</td>\n",
       "      <td>fields__oSets__oPoints__observations__eVnum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fields__oSets__growthStage Zadoks</td>\n",
       "      <td>fields__oSets__oPoints__observations__a1__number EGA</td>\n",
       "      <td>fields__oSets__oPoints__observations__a2__number BCO</td>\n",
       "      <td>fields__oSets__oPoints__observations__a3__number Greenbug</td>\n",
       "      <td>fields__oSets__oPoints__observations__anum TotalAPhids</td>\n",
       "      <td>fields__oSets__oPoints__observations__eVnum Natural enemy totals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0  \\\n",
       "0  fields__oSets__growthStage          \n",
       "1  fields__oSets__growthStage Zadoks   \n",
       "\n",
       "                                                      1  \\\n",
       "0  fields__oSets__oPoints__observations__a1__number       \n",
       "1  fields__oSets__oPoints__observations__a1__number EGA   \n",
       "\n",
       "                                                      2  \\\n",
       "0  fields__oSets__oPoints__observations__a2__number       \n",
       "1  fields__oSets__oPoints__observations__a2__number BCO   \n",
       "\n",
       "                                                           3  \\\n",
       "0  fields__oSets__oPoints__observations__a3__number            \n",
       "1  fields__oSets__oPoints__observations__a3__number Greenbug   \n",
       "\n",
       "                                                        4  \\\n",
       "0  fields__oSets__oPoints__observations__anum               \n",
       "1  fields__oSets__oPoints__observations__anum TotalAPhids   \n",
       "\n",
       "                                                                  5  \n",
       "0  fields__oSets__oPoints__observations__eVnum                       \n",
       "1  fields__oSets__oPoints__observations__eVnum Natural enemy totals  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(column_grid.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the column width, since we're done looking at the names this way\n",
    "pandas.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we concatenate, we'll standardize on the names from the first sheet (0), since it's more regular. But which sheet is the one to fix? Which sheet has `fields__oSets__growthStage Zadoks` instead of `fields__oSets__growthStage`? I believe \"Erl\" was our base for comparison initially, but let's make sure of what we're about to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Bad:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Erl'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a filtered dictionary, for later reference\n",
    "sheets_with_bad_column_names = {sheet_name: sheet for sheet_name, sheet in sheets.items() \n",
    "                                if 'fields__oSets__growthStage Zadoks' in sheet.columns}\n",
    "display(heading('Bad:'),\n",
    "        set(sheets_with_bad_column_names.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Good:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Tyler'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(heading('Good:'),\n",
    "        set(sheets.keys()) - set(sheets_with_bad_column_names.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, \"Tyler\" has the column names we prefer, \"Erl\" does not. Duly noted.\n",
    "\n",
    "There's now a `sheets_with_bad_column_names` variable we can use when we fix that. (It's only got one DataFrame, but it's still good practice to be ready for batch processing in case this code is reused in the future.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How shall we solve the name mismatch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our options:\n",
    "\n",
    "- rename the columns\n",
    "- try to merge the sheets in a way that ignores the column names of the bad sheet\n",
    "\n",
    "If we try to do a special merge, ignoring the column names, we have to worry about the _precise order_ of those columns instead of relying on the names. Since we'd have to spend time checking—and possibly rearranging—the column sequence, we might as well spend that time creating a _reusable_, documented solution for quick and painless name fixing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How (where) should we rename the columns/indices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibilities:\n",
    "\n",
    "- fix the spreadsheet document in Excel format, and move ahead as if this had never happened\n",
    "- keep the names in the file, but correct the names in memory once they become indices\n",
    "\n",
    "Since this notebook you're reading has already mentioned the problem, let's go ahead and solve it here. That way our notebook will detail the fix and how to use it in the future, if there are more Excel spreadsheets with similarly altered names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming axis labels (columns or rows) with _pandas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ has a [`rename`] method which lets us apply a transform function to the indices named after our worksheet columns (or explicitly map each column through a dictionary).\n",
    "\n",
    "[`rename`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html\n",
    "\n",
    "Since the bad names merely have extra words tacked onto the end, let's just split the name and use the first \"word\". In Python, we get the first item of a sequence by using index zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word(string, word_separator=' '):\n",
    "    \"\"\" Split string into words (by space character), return first word. \"\"\"\n",
    "    return string.split(word_separator)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to apply this function to every Series in the DataFrame, through the _pandas_ rename function. For the sake of visualizing the changes, let's also report on changes in a dry run before using the _pandas_ rename function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Erl</h3><ol><li>fields__client__company</li><li>fields__client__name</li><li>fields__client__fname</li><li>fields__client__lname</li><li>fields__client__displayText</li><li>fields__name</li><li>fields__crop</li><li>fields__desc</li><li>fields__image</li><li>fields__date</li><li>fields__oSets__date</li><li>fields__oSets__dateCompare</li><li style='font-weight: bold'>fields__oSets__growthStage Zadoks &rarr; fields__oSets__growthStage</li><li>fields__oSets__desc</li><li>fields__oSets__obsName</li><li>fields__oSets__totalSets</li><li>fields__oSets__completeSets</li><li>fields__oSets__results</li><li>fields__oSets__oPoints__id</li><li>fields__oSets__oPoints__name</li><li>fields__oSets__oPoints__observations__id</li><li>fields__oSets__oPoints__observations__name</li><li>fields__oSets__oPoints__observations__enum</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__eVnum Natural enemy totals &rarr; fields__oSets__oPoints__observations__eVnum</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__anum TotalAPhids &rarr; fields__oSets__oPoints__observations__anum</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__a1__number EGA &rarr; fields__oSets__oPoints__observations__a1__number</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__a2__number BCO &rarr; fields__oSets__oPoints__observations__a2__number</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__a3__number Greenbug &rarr; fields__oSets__oPoints__observations__a3__number</li><li>fields__oSets__oPoints__observations__disabled</li><li>fields__oSets__oPoints__observations__complete</li><li>fields__oSets__oPoints__observations__|</li><li>fields__oSets__oPoints__observations__|__number</li><li>fields__oSets__oPoints__location__coords__latitude</li><li>fields__oSets__oPoints__location__coords__longitude</li><li>fields__oSets__oPoints__location__coords__accuracy</li><li>fields__oSets__oPoints__location__coords__altitude</li><li>fields__oSets__oPoints__location__coords__heading</li><li>fields__oSets__oPoints__location__coords__speed</li><li>fields__oSets__oPoints__location__coords__altitudeAccuracy</li><li>fields__oSets__oPoints__location__timestamp</li><li>fields__oSets__totalA1</li><li>fields__oSets__totalA2</li><li>fields__oSets__totalA3</li><li>fields__oSets__totalA4</li><li>clients__company</li><li>clients__name</li><li>clients__fname</li><li>clients__lname</li><li>clients__displayText</li><li>observers</li></ol>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = []  # For the lines of the report which we'll display later.\n",
    "\n",
    "for sheet_name, sheet in sheets_with_bad_column_names.items():\n",
    "    report.append(make_heading(sheet_name, level=3))  # heading\n",
    "    report_lines = []  # the body of the report for each DataFrame\n",
    "    for column_name in sheet.columns:\n",
    "        after = first_word(column_name)\n",
    "        if after == column_name:\n",
    "            content = column_name\n",
    "            attributes = None\n",
    "        else:\n",
    "            content = f\"{column_name} &rarr; {after}\"  # old --> new\n",
    "            attributes = \"style='font-weight: bold'\"\n",
    "        report_lines.append(html_wrap(content, 'li', attributes))  # add an HTML list item\n",
    "    report.append(html_wrap(''.join(report_lines), 'ol')) # add an ordered list of items to the report\n",
    "    \n",
    "# join all the strings together and display as HTML\n",
    "display(HTML(''.join(report)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually change the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in sheets_with_bad_column_names.values():\n",
    "    sheet.rename(mapper=first_word, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, we know there's only one sheet, so the `for` loop isn't absolutely necessary, but it's still a good habit when dealing with reusable scripts that can work on batches of datasets. (Sometimes other people find your work useful, and sometimes you'll revisit your work to copy something that succeeded in the past.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally uniting our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.concat(sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4690 entries, (Erl, 0) to (Tyler, 3779)\n",
      "Columns: 50 entries, clients__company to observers\n",
      "dtypes: datetime64[ns](1), float64(27), object(22)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splendid! That's what we expected. 😁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of really long, repetitive column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ has a concept of [indexing hierarchically], which may help group columns together. However, I'm new to _pandas_ and I'm not new to Python. Furthermore, from what I've read, if we use a multi-level labelling system for grouping, we have to pay attention to which level we're operating on as we work with the spreadsheet as DataFrame. \n",
    "\n",
    "To avoid complications due to my own ignorance, let's use a nested dictionary in Python to accomplish the same thing without _pandas_. We can probably use the dictionary to help us add more indices to the DataFrame later, if we need.\n",
    "\n",
    "[indexing hierarchically]: https://pandas.pydata.org/pandas-docs/stable/advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested dictionaries, for a hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a regular dictionary in Python, let's use something called a [`defaultdict`], which will simplify the creation of our hierarchy. [`defaultdict`] is like a regular dictionary, except it doesn't complain if you try to access a key that doesn't exist yet—it just adds it.\n",
    "\n",
    "[`defaultdict`]: https://docs.python.org/3/library/collections.html#collections.defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there's always the chance that a node might have data as well as more nodes under it, we'll store the reference to data in a key that can't possibly be a segment in the name: the separator (which in this case is '__') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method looks long but it's mostly comments for your benefit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def split_column_to_dict(column, column_name=None, column_dictionary=None, separator='__'):\n",
    "    \"\"\" Split the column names like \"fields__oSets__oPoints__observations\" into groupings of keys\n",
    "    so that related keys are easy to find, ie columns['fields']['oSets']['oPoints']['observations'].\n",
    "    This produces a tree of column name segments, with references to actual data at the ends.\n",
    "    \n",
    "    If `column_name` is provided, it's used instead of the actual column name.\n",
    "    \n",
    "    If `column_dicitonary` is provided, attempt to add to it as if it were already initialized as\n",
    "    a nested defaultdict, from an earlier call to this function. \"\"\"\n",
    "\n",
    "    # If a dictionary is not provided, make an empty one.\n",
    "    if column_dictionary is None:\n",
    "        def nested_dict():\n",
    "            \"\"\" This function will be called by defaultdict\n",
    "            whenever a non-existent key is used. \"\"\"\n",
    "            return defaultdict(nested_dict)\n",
    "        \n",
    "        column_dictionary = nested_dict()\n",
    "\n",
    "    # Set a pointer to the root of the tree, for starters.\n",
    "    pointer = column_dictionary\n",
    "    \n",
    "    # Now, walk through the segments in order from left to right,\n",
    "    # touching the tree for each one.\n",
    "    for segment in str(column_name or column.name).split(separator):\n",
    "        pointer = pointer[segment]\n",
    "        \n",
    "    # Now that the loop is done, the pointer is pointing at the deepest\n",
    "    # level of the branch, which either already existed or else it was created.\n",
    "    \n",
    "    # At the end of the branch, put the data under a special key.\n",
    "    pointer[separator] = column\n",
    "\n",
    "    # Since `pointer` was actually just pointing to parts of `column_dictionary`,\n",
    "    # the column dictionary has been filled out with nodes because of how defaultdict\n",
    "    # was setup with our `nested_dict` constructor.\n",
    "    return column_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to demonstrate that the functional code is actually quite slim and simple, here it is without any comments:\n",
    "\n",
    "```python\n",
    "def split_column_to_dict(dataframe, column_name, column_dictionary=None, separator='__'):\n",
    "    if column_dictionary is None:\n",
    "        def nested_dict():\n",
    "            return defaultdict(nested_dict)\n",
    "        column_dictionary = nested_dict()\n",
    "    pointer = column_dictionary\n",
    "    for segment in str(column_name or column.name).split(separator):\n",
    "        pointer = pointer[segment]\n",
    "    pointer[separator] = dataframe[column_name]\n",
    "    return column_dictionary\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Now, make a dictionary of column trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_dictionary = None  # initialize the variable, otherwise we can't reference it\n",
    "separator = '__'\n",
    "for name, column in data.items():\n",
    "    column_dictionary = split_column_to_dict(column, name, column_dictionary, separator)\n",
    "# Turn off the defaultdict behaviour, so errors are easier to detect later on\n",
    "column_dictionary.default_factory = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that worked as planned, there should be a list of the first segments of all the column names in that sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['clients', 'fields', 'observers'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing deeper, more segments that share a common prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['client', 'crop', 'date', 'desc', 'image', 'name', 'oSets'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields_node = column_dictionary['fields']\n",
    "fields_node.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['completeSets', 'date', 'dateCompare', 'desc', 'growthStage', 'oPoints', 'obsName', 'results', 'totalA1', 'totalA2', 'totalA3', 'totalA4', 'totalSets'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_node = fields_node['oSets']\n",
    "sets_node.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of each branch in the tree should be a '\\_\\_' key for the actual data. For example, the `date` of the set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_node['date'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at that data right now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Erl  0     2017-08-02T13:12:09.542\n",
       "     1                         NaN\n",
       "     2                         NaN\n",
       "     3                         NaN\n",
       "     4                         NaN\n",
       "     5                         NaN\n",
       "     6                         NaN\n",
       "     7                         NaN\n",
       "     8                         NaN\n",
       "     9                         NaN\n",
       "     10                        NaN\n",
       "     11                        NaN\n",
       "     12                        NaN\n",
       "     13                        NaN\n",
       "     14                        NaN\n",
       "     15                        NaN\n",
       "     16                        NaN\n",
       "     17                        NaN\n",
       "     18                        NaN\n",
       "     19                        NaN\n",
       "Name: fields__oSets__date, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_node['date'][separator].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is the problem with which we launched this whole endeavour. Many, many empty cells. If we want to skip over blanks as we scan down a column, _pandas_ has a [`dropna()`] method for that. Let's use `head` to peek at the first bit of that:\n",
    "\n",
    "[`dropna()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Erl    0      2017-08-02T13:12:09.542\n",
       "       70     2017-08-09T09:25:11.710\n",
       "       140    2017-08-09T10:06:25.480\n",
       "       210    2017-08-09T11:21:01.555\n",
       "       350    2017-08-09T11:37:20.862\n",
       "       490    2017-08-22T15:42:05.751\n",
       "       560    2017-08-17T11:12:02.820\n",
       "       700    2017-08-17T13:06:30.183\n",
       "       840    2017-08-22T16:02:50.682\n",
       "Tyler  0      2017-07-14T12:31:24.194\n",
       "Name: fields__oSets__date, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_node['date'][separator].dropna().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So much better!\n",
    "\n",
    "We now have enough information to find the beginning of chunks in the sheet by scanning for non-blank cells: we have those row numbers for each of the non-null records of that column, where related columns will also reveal data we need for that section.\n",
    "\n",
    "As a side note, the number of non-null (not empty) records in any given column was displayed when we called [`info()`] on the DataFrame. We can also get information like that from the column (which is a Series in _pandas_) by using [`describe()`] or [`count()`]:\n",
    "\n",
    "[`info()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\n",
    "[`describe()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.describe.html\n",
    "[`count()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.count.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                          54\n",
       "unique                         54\n",
       "top       2017-08-02T13:12:09.542\n",
       "freq                            1\n",
       "Name: fields__oSets__date, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_node['date'][separator].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions, for browsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we start actually reading groups of columns based on which type of chunk we're reading from, we'll have to start typing lists of column names for each section.\n",
    "\n",
    "It's a bit of extra work to pay attention to whether a given node in the hierarchy is holding a reference to a data Series (column) or whether it's only an intermediate step on the way to the end of the branch.\n",
    "\n",
    "To save time and mental energy, we can filter columns by whether they have data or not, if we make some simple filter functions. For detecting data that we've placed in the hierarchy of columns, we can look for the special key that we chose earlier: the separator, which is two underscore characters (`__`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_data(node):\n",
    "    \"\"\" Filter children that have data. We know a child item has data if\n",
    "    it has a key that's the just the separator string. \"\"\"\n",
    "    return {parent_key: child for parent_key, child in node.items()\n",
    "            if separator in child.keys()}\n",
    "\n",
    "\n",
    "def has_children(node):\n",
    "    \"\"\" Filter children that have children. We know an item has children if\n",
    "    it has at least one key that isn't just the separator string, which is the\n",
    "    special key for data references. \"\"\"\n",
    "    return {parent_key: child for parent_key, child in node.items()\n",
    "            if len([key for key in child.keys() if key != separator]) >= 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>children with children:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['a1', 'a2', 'a3', '|'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_node = sets_node['oPoints']\n",
    "observations_node = points_node['observations']\n",
    "display(heading('children with children:'),\n",
    "        has_children(observations_node).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>children with data:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['anum', 'complete', 'disabled', 'eVnum', 'enum', 'id', 'name', '|'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(heading('children with data:'),\n",
    "        has_data(observations_node).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>children with children & data:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'|'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set of keys for nodes that that have children but also data:\n",
    "display(heading('children with children & data:'),\n",
    "        set(has_children(observations_node).keys()) & set(has_data(observations_node).keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal thought:\n",
    "\n",
    "I have to wonder why the developers of the app that output this data chose to use an unpronounceable column name, and put something important there.\n",
    "\n",
    "Regardless, we can effortlessly handle it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: accurately reading sections at will"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the columns containing data about observation sets.\n",
    "\n",
    "We'll use `has_data` to filter our `sets_node` so we can express a list of names of data-containing columns about `fields__oSets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fields__oSets__completeSets',\n",
       " 'fields__oSets__date',\n",
       " 'fields__oSets__dateCompare',\n",
       " 'fields__oSets__desc',\n",
       " 'fields__oSets__growthStage',\n",
       " 'fields__oSets__obsName',\n",
       " 'fields__oSets__results',\n",
       " 'fields__oSets__totalA1',\n",
       " 'fields__oSets__totalA2',\n",
       " 'fields__oSets__totalA3',\n",
       " 'fields__oSets__totalA4',\n",
       " 'fields__oSets__totalSets']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sets_columns_names = [column[separator].name for column in has_data(sets_node).values()]\n",
    "display(sets_columns_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing that list to _pandas_, we should get exactly which columns of data we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fields__oSets__completeSets</th>\n",
       "      <th>fields__oSets__date</th>\n",
       "      <th>fields__oSets__dateCompare</th>\n",
       "      <th>fields__oSets__desc</th>\n",
       "      <th>fields__oSets__growthStage</th>\n",
       "      <th>fields__oSets__obsName</th>\n",
       "      <th>fields__oSets__results</th>\n",
       "      <th>fields__oSets__totalA1</th>\n",
       "      <th>fields__oSets__totalA2</th>\n",
       "      <th>fields__oSets__totalA3</th>\n",
       "      <th>fields__oSets__totalA4</th>\n",
       "      <th>fields__oSets__totalSets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Erl</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-02T13:12:09.542</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fields__oSets__completeSets      fields__oSets__date  \\\n",
       "Erl 0                          0.0  2017-08-02T13:12:09.542   \n",
       "    1                          NaN                      NaN   \n",
       "    2                          NaN                      NaN   \n",
       "    3                          NaN                      NaN   \n",
       "    4                          NaN                      NaN   \n",
       "\n",
       "      fields__oSets__dateCompare  fields__oSets__desc  \\\n",
       "Erl 0                 2017-08-02                  NaN   \n",
       "    1                        NaT                  NaN   \n",
       "    2                        NaT                  NaN   \n",
       "    3                        NaT                  NaN   \n",
       "    4                        NaT                  NaN   \n",
       "\n",
       "       fields__oSets__growthStage fields__oSets__obsName  \\\n",
       "Erl 0                         7.0                  Tyler   \n",
       "    1                         NaN                    NaN   \n",
       "    2                         NaN                    NaN   \n",
       "    3                         NaN                    NaN   \n",
       "    4                         NaN                    NaN   \n",
       "\n",
       "      fields__oSets__results  fields__oSets__totalA1  fields__oSets__totalA2  \\\n",
       "Erl 0                    NaN                     NaN                     NaN   \n",
       "    1                    NaN                     NaN                     NaN   \n",
       "    2                    NaN                     NaN                     NaN   \n",
       "    3                    NaN                     NaN                     NaN   \n",
       "    4                    NaN                     NaN                     NaN   \n",
       "\n",
       "       fields__oSets__totalA3  fields__oSets__totalA4  \\\n",
       "Erl 0                     NaN                     NaN   \n",
       "    1                     NaN                     NaN   \n",
       "    2                     NaN                     NaN   \n",
       "    3                     NaN                     NaN   \n",
       "    4                     NaN                     NaN   \n",
       "\n",
       "       fields__oSets__totalSets  \n",
       "Erl 0                       1.0  \n",
       "    1                       NaN  \n",
       "    2                       NaN  \n",
       "    3                       NaN  \n",
       "    4                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[sets_columns_names].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the problem we faced at the outset. How about skipping irrelevant rows? We fixed this earlier with `dropna()`, but this time we're operating on some columns that _may_ be null, plus certain ones that _must not_ be null.\n",
    "\n",
    "Let's use the date column as the crucial record upon which we'll predicate our filter, because it should never be null. \n",
    "\n",
    "_pandas_ has a way to filter on conditions, which is sometimes called [boolean indexing] because the condition is either `True` or `False`. In this case, _pandas_ expects the actual column data object itself (Series), rather than just the name of the column to check. We already have that in the hierarchy from earlier:\n",
    "\n",
    "[boolean indexing]: https://pandas.pydata.org/pandas-docs/stable/10min.html#boolean-indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the date column as the crucial record upon which we'll predicate our filter. In this case, _pandas_ expects the actual column data object itself (Series), rather than just the name of the column to check. We already have that in the hierarchy from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_column = sets_node['date'][separator]\n",
    "type(date_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a check for whether the value is null to _pandas_, as well as specifying the column names we want to get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fields__oSets__completeSets</th>\n",
       "      <th>fields__oSets__date</th>\n",
       "      <th>fields__oSets__dateCompare</th>\n",
       "      <th>fields__oSets__desc</th>\n",
       "      <th>fields__oSets__growthStage</th>\n",
       "      <th>fields__oSets__obsName</th>\n",
       "      <th>fields__oSets__results</th>\n",
       "      <th>fields__oSets__totalA1</th>\n",
       "      <th>fields__oSets__totalA2</th>\n",
       "      <th>fields__oSets__totalA3</th>\n",
       "      <th>fields__oSets__totalA4</th>\n",
       "      <th>fields__oSets__totalSets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">Erl</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-02T13:12:09.542</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-09T09:25:11.710</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-09T10:06:25.480</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-08-09T11:21:01.555</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Stean</td>\n",
       "      <td>RESULTS.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-08-09T11:37:20.862</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Stean</td>\n",
       "      <td>RESULTS.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-22T15:42:05.751</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Mikki</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-08-17T11:12:02.820</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Gabrielle</td>\n",
       "      <td>RESULTS.1</td>\n",
       "      <td>169.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-08-17T13:06:30.183</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Stean</td>\n",
       "      <td>RESULTS.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-22T16:02:50.682</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Mikki</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Tyler</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-14T12:31:24.194</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-07-18T10:31:22.263</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-07-28T13:05:44.673</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Mikki</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-01T15:27:40.174</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Stean</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-04T10:18:29.654</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Stean</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-07-18T10:51:30.195</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fields__oSets__completeSets      fields__oSets__date  \\\n",
       "Erl   0                            0.0  2017-08-02T13:12:09.542   \n",
       "      70                           1.0  2017-08-09T09:25:11.710   \n",
       "      140                          1.0  2017-08-09T10:06:25.480   \n",
       "      210                          2.0  2017-08-09T11:21:01.555   \n",
       "      350                          2.0  2017-08-09T11:37:20.862   \n",
       "      490                          1.0  2017-08-22T15:42:05.751   \n",
       "      560                          2.0  2017-08-17T11:12:02.820   \n",
       "      700                          2.0  2017-08-17T13:06:30.183   \n",
       "      840                          1.0  2017-08-22T16:02:50.682   \n",
       "Tyler 0                            0.0  2017-07-14T12:31:24.194   \n",
       "      70                           1.0  2017-07-18T10:31:22.263   \n",
       "      140                          1.0  2017-07-28T13:05:44.673   \n",
       "      210                          1.0  2017-08-01T15:27:40.174   \n",
       "      280                          1.0  2017-08-04T10:18:29.654   \n",
       "      350                          1.0  2017-07-18T10:51:30.195   \n",
       "\n",
       "          fields__oSets__dateCompare  fields__oSets__desc  \\\n",
       "Erl   0                   2017-08-02                  NaN   \n",
       "      70                  2017-08-09                  NaN   \n",
       "      140                 2017-08-09                  NaN   \n",
       "      210                 2017-08-09                  NaN   \n",
       "      350                 2017-08-09                  NaN   \n",
       "      490                 2017-08-22                  NaN   \n",
       "      560                 2017-08-17                  NaN   \n",
       "      700                 2017-08-17                  NaN   \n",
       "      840                 2017-08-22                  NaN   \n",
       "Tyler 0                   2017-07-14                  NaN   \n",
       "      70                  2017-07-18                  NaN   \n",
       "      140                 2017-07-28                  NaN   \n",
       "      210                 2017-08-01                  NaN   \n",
       "      280                 2017-08-04                  NaN   \n",
       "      350                 2017-07-18                  NaN   \n",
       "\n",
       "           fields__oSets__growthStage fields__oSets__obsName  \\\n",
       "Erl   0                           7.0                  Tyler   \n",
       "      70                          8.0                  Tyler   \n",
       "      140                         7.0                  Tyler   \n",
       "      210                         9.0                  Stean   \n",
       "      350                         8.0                  Stean   \n",
       "      490                         8.0                  Mikki   \n",
       "      560                         8.0              Gabrielle   \n",
       "      700                         9.0                  Stean   \n",
       "      840                         8.0                  Mikki   \n",
       "Tyler 0                           6.0                  Tyler   \n",
       "      70                          6.0                  Tyler   \n",
       "      140                         8.0                  Mikki   \n",
       "      210                         8.0                  Stean   \n",
       "      280                         8.5                  Stean   \n",
       "      350                         6.0                  Tyler   \n",
       "\n",
       "          fields__oSets__results  fields__oSets__totalA1  \\\n",
       "Erl   0                      NaN                     NaN   \n",
       "      70               RESULTS.5                   164.0   \n",
       "      140              RESULTS.5                    66.0   \n",
       "      210              RESULTS.1                     0.0   \n",
       "      350              RESULTS.1                     5.0   \n",
       "      490              RESULTS.5                     1.0   \n",
       "      560              RESULTS.1                   169.0   \n",
       "      700              RESULTS.1                    78.0   \n",
       "      840              RESULTS.5                   187.0   \n",
       "Tyler 0                      NaN                     NaN   \n",
       "      70               RESULTS.5                     8.0   \n",
       "      140              RESULTS.5                    37.0   \n",
       "      210              RESULTS.5                    52.0   \n",
       "      280              RESULTS.5                    47.0   \n",
       "      350              RESULTS.5                     2.0   \n",
       "\n",
       "           fields__oSets__totalA2  fields__oSets__totalA3  \\\n",
       "Erl   0                       NaN                     NaN   \n",
       "      70                      0.0                     0.0   \n",
       "      140                     0.0                     0.0   \n",
       "      210                     0.0                     0.0   \n",
       "      350                     5.0                     0.0   \n",
       "      490                     0.0                     0.0   \n",
       "      560                    96.0                     0.0   \n",
       "      700                   102.0                     0.0   \n",
       "      840                     0.0                     0.0   \n",
       "Tyler 0                       NaN                     NaN   \n",
       "      70                      0.0                     0.0   \n",
       "      140                     0.0                     0.0   \n",
       "      210                     0.0                     0.0   \n",
       "      280                     0.0                     0.0   \n",
       "      350                     0.0                     0.0   \n",
       "\n",
       "           fields__oSets__totalA4  fields__oSets__totalSets  \n",
       "Erl   0                       NaN                       1.0  \n",
       "      70                      0.0                       1.0  \n",
       "      140                     0.0                       1.0  \n",
       "      210                     0.0                       2.0  \n",
       "      350                     0.0                       2.0  \n",
       "      490                     0.0                       1.0  \n",
       "      560                     0.0                       2.0  \n",
       "      700                     0.0                       2.0  \n",
       "      840                     0.0                       1.0  \n",
       "Tyler 0                       NaN                       1.0  \n",
       "      70                      0.0                       1.0  \n",
       "      140                     0.0                       1.0  \n",
       "      210                     0.0                       1.0  \n",
       "      280                     0.0                       1.0  \n",
       "      350                     0.0                       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sets = data[date_column.isna() == False][sets_columns_names]\n",
    "display(sets.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can repeat this technique to get all the other section data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
