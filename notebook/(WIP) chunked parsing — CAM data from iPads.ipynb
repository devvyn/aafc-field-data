{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Python and _pandas_, read two Excel worksheets, merge the data, and make the data available for analysis.\n",
    "\n",
    "- Final data should be exported to Excel format, and should be easy to download.\n",
    "- Results must be reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare, we need to be able to open the Excel files, display results of intermediate processing in the notebook, and avoid repeating large blocks of code.\n",
    "\n",
    "Some functions can be imported, as they're already available publicly. Others will be made here, in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The display function isn't always imported by default in some Jupyter implementations.\n",
    "# We'll probably use it a lot.\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter can output HTML if we want. Here are simple helpers to make headings\n",
    "and other embellishments easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_wrap(content, element=\"span\", attributes=None):\n",
    "    \"\"\" Convenience method for wrapping any string in an HTML tag. \"\"\"\n",
    "    element_with_attributes = ' '.join((item for item in (element, attributes) if not item is None))\n",
    "    tag_open = f\"<{element_with_attributes}>\"\n",
    "    tag_close = f\"</{element}>\"\n",
    "    return f\"{tag_open}{content}{tag_close}\"\n",
    "\n",
    "\n",
    "def make_heading(content, level=5):\n",
    "    \"\"\" Convenience method for wrapping any string in an HTML header tag. \"\"\"\n",
    "    element = f\"h{level}\"\n",
    "    return html_wrap(content, element)\n",
    "\n",
    "\n",
    "def heading(*args, **kwargs):\n",
    "    \"\"\" Call IPython.core.display.HTML on the results of the make_heading function,\n",
    "    so users don't have to repeatedly do `HTML(heading(…))` \"\"\"\n",
    "    return HTML(make_heading(*args, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[_pandas_] is really good with columnar data, like Excel files:\n",
    "\n",
    "[_pandas_]: https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Excel workbook: `2017 CAM data from iPads.xlxs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file I'm interested in parsing for cleanup:\n",
    "file_path = \"./src/real data/2017 CAM data from iPads/2017 CAM data from iPads.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017 CAM data Erl',\n",
       " '2017 CAM iPad data Tyler',\n",
       " 'Combined iPad 2017 CAM data',\n",
       " 'schema (WIP reverse engineer)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = pandas.ExcelFile(file_path)\n",
    "sorted(data_file.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm only interested in first two, for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_sheet_names = _[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dictionary of dataframes from all the sheets, using the last word as the name. In Python, an index of -1 means the last item, as in, one less than the largest index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_word(string, word_separator=' '):\n",
    "    return string.split(' ')[-1]\n",
    "\n",
    "\n",
    "sheets = {last_word(sheet_name): data_file.parse(sheet_name)\n",
    "          for sheet_name in cam_sheet_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Erl', 'Tyler'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The keys are sheet names. Let's see what we've got:\n",
    "sheets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a convenient list of sheets that are loaded as _pandas_ DataFrames, we can work toward merging them into one. Once they're merged, we can process the data more easily from a single DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries in Python are just a collection of named things. The things can be another dictionary, a string, a number, or whatver. Even the names of the things don't necessarily have to be words—they can be numbers, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary:\n",
    "my_dictionary = {\n",
    "    'one': 1,\n",
    "    2: 'two',\n",
    "    'green': 'I like colour green.',\n",
    "    'another dictionary': {'more stuff': 1024,\n",
    "                           'even more stuff': 2048},\n",
    "    'a list': [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall something from that dictionary:\n",
    "my_dictionary[\"one\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary[\"another dictionary\"][\"even more stuff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attempt to use a non-existant key results in a Python exception called a `KeyError`. This is helpful if you accidentally lose track of which keys are in the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"some key that doesn't exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6706547ecbde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"some key that doesn't exist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"some key that doesn't exist\""
     ]
    }
   ],
   "source": [
    "my_dictionary[\"some key that doesn't exist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want an this to happen, there are ways to get around it. Later on, we'll use something called a [`defaultdict`], which just makes up the new key on the spot, instead of stopping dead.\n",
    "\n",
    "[`defaultdict`]: https://docs.python.org/3/library/collections.html?highlight=defaultdict#defaultdict-objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `for` with dictionaries in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `for` statements are handy for doing something to each item in a collection. Dictionaries are a type of collection, but since they have keys and values, you need to specify which you want. To address this, there are three handy methods that all dictionaries have:\n",
    "\n",
    "- `keys()` - Only the key names\n",
    "- `values()` - Only the values\n",
    "- `items()` - Pairs of keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'green'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'another dictionary'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'a list'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in my_dictionary.keys():\n",
    "    display(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I like colour green.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'more stuff': 1024, 'even more stuff': 2048}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for value in my_dictionary.values():\n",
    "    display(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('one', 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 'two')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('green', 'I like colour green.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('another dictionary', {'more stuff': 1024, 'even more stuff': 2048})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('a list', [1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in my_dictionary.items():\n",
    "    display(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning more about lists, dictionaries, and other data structures in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about using dictionaries, see the official [Python tutorial on dictionaries], which is part of the page demonstrating other Python collections, such as [lists], which we'll be using extensively.\n",
    "\n",
    "[Python tutorial on dictionaries]: https://docs.python.org/3/tutorial/datastructures.html#dictionaries\n",
    "[lists]: https://docs.python.org/3/tutorial/datastructures.html#more-on-lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniting the DataFrames (worksheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _pandas_ functions for merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ has multiple methods for combining datasets:\n",
    "\n",
    "- [`concat`]: The concatenate method has an option to ignore row numbers, which has the effect of gluing each dataframe to the bottom of the previous one.\n",
    "- [`append`]: Append would be almost equivalent, but always updates the first DataFrame or Series it's given.\n",
    "- [`merge`]: Merge is more for database-style relational merges.\n",
    "\n",
    "[`concat`]: https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "[`append`]: https://pandas.pydata.org/pandas-docs/stable/merging.html#concatenating-using-append\n",
    "[`merge`]: https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n",
    "\n",
    "From reading up on all three methods, it looks to me like `concat` will suffice, here, as long as the column names are identical. I like to have the option of creating a new DataFrame rather than overwriting anything, because the results are easier to repeat.\n",
    "\n",
    "Let's see how close that concatenation method gets us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4690 entries, 0 to 4689\n",
      "Data columns (total 56 columns):\n",
      "clients__company                                                    1 non-null object\n",
      "clients__displayText                                                1 non-null object\n",
      "clients__fname                                                      1 non-null object\n",
      "clients__lname                                                      1 non-null object\n",
      "clients__name                                                       1 non-null object\n",
      "fields__client__company                                             21 non-null object\n",
      "fields__client__displayText                                         21 non-null object\n",
      "fields__client__fname                                               21 non-null object\n",
      "fields__client__lname                                               21 non-null object\n",
      "fields__client__name                                                21 non-null object\n",
      "fields__crop                                                        21 non-null object\n",
      "fields__date                                                        21 non-null object\n",
      "fields__desc                                                        15 non-null object\n",
      "fields__image                                                       21 non-null object\n",
      "fields__name                                                        21 non-null object\n",
      "fields__oSets__completeSets                                         54 non-null float64\n",
      "fields__oSets__date                                                 54 non-null object\n",
      "fields__oSets__dateCompare                                          54 non-null datetime64[ns]\n",
      "fields__oSets__desc                                                 0 non-null float64\n",
      "fields__oSets__growthStage                                          45 non-null float64\n",
      "fields__oSets__growthStage Zadoks                                   9 non-null float64\n",
      "fields__oSets__oPoints__id                                          335 non-null float64\n",
      "fields__oSets__oPoints__location__coords__accuracy                  250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__altitude                  250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__altitudeAccuracy          250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__heading                   247 non-null float64\n",
      "fields__oSets__oPoints__location__coords__latitude                  250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__longitude                 250 non-null float64\n",
      "fields__oSets__oPoints__location__coords__speed                     250 non-null float64\n",
      "fields__oSets__oPoints__location__timestamp                         250 non-null float64\n",
      "fields__oSets__oPoints__name                                        335 non-null object\n",
      "fields__oSets__oPoints__observations__a1__number                    324 non-null float64\n",
      "fields__oSets__oPoints__observations__a1__number EGA                124 non-null float64\n",
      "fields__oSets__oPoints__observations__a2__number                    112 non-null float64\n",
      "fields__oSets__oPoints__observations__a2__number BCO                30 non-null float64\n",
      "fields__oSets__oPoints__observations__a3__number                    25 non-null float64\n",
      "fields__oSets__oPoints__observations__a3__number Greenbug           0 non-null float64\n",
      "fields__oSets__oPoints__observations__anum                          1350 non-null float64\n",
      "fields__oSets__oPoints__observations__anum TotalAPhids              325 non-null float64\n",
      "fields__oSets__oPoints__observations__complete                      1937 non-null float64\n",
      "fields__oSets__oPoints__observations__disabled                      0 non-null float64\n",
      "fields__oSets__oPoints__observations__eVnum                         270 non-null float64\n",
      "fields__oSets__oPoints__observations__eVnum Natural enemy totals    65 non-null float64\n",
      "fields__oSets__oPoints__observations__enum                          335 non-null float64\n",
      "fields__oSets__oPoints__observations__id                            2010 non-null float64\n",
      "fields__oSets__oPoints__observations__name                          2010 non-null object\n",
      "fields__oSets__oPoints__observations__|                             3015 non-null object\n",
      "fields__oSets__oPoints__observations__|__number                     172 non-null float64\n",
      "fields__oSets__obsName                                              54 non-null object\n",
      "fields__oSets__results                                              52 non-null object\n",
      "fields__oSets__totalA1                                              52 non-null float64\n",
      "fields__oSets__totalA2                                              52 non-null float64\n",
      "fields__oSets__totalA3                                              52 non-null float64\n",
      "fields__oSets__totalA4                                              52 non-null float64\n",
      "fields__oSets__totalSets                                            54 non-null float64\n",
      "observers                                                           3 non-null object\n",
      "dtypes: datetime64[ns](1), float64(33), object(22)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "pandas.concat(sheets, ignore_index=True).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the RangeIndex size in the info: \n",
    "\n",
    ">4690 entries, 0 to 4689\n",
    "\n",
    "Which means 4690 \"rows\", if this were a spreadsheet.\n",
    "\n",
    "Compared to the total row count for all sheets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(sheet) for sheet in sheets.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, so far, except for some variations in the column names—I see `growthStage` and `growthStage Zadoks`, as well as some aphid names amongst the `a1__number`, `a2__number`, `a3__number` group:\n",
    "\n",
    "```\n",
    "fields__oSets__growthStage                                  45 non-null float64\n",
    "fields__oSets__growthStage Zadoks                           9 non-null float64\n",
    "```\n",
    "\n",
    "```\n",
    "fields__oSets__oPoints__observations__a1__number            324 non-null float64\n",
    "fields__oSets__oPoints__observations__a1__number EGA        124 non-null float64\n",
    "fields__oSets__oPoints__observations__a2__number            112 non-null float64\n",
    "fields__oSets__oPoints__observations__a2__number BCO        30 non-null float64\n",
    "fields__oSets__oPoints__observations__a3__number            25 non-null float64\n",
    "fields__oSets__oPoints__observations__a3__number Greenbug   0 non-null float64\n",
    "```\n",
    "\n",
    "The total number of rows is correct, and the other columns line up when the names match.\n",
    "\n",
    "Column names (which become Series names in _pandas_) are the only problem standing in the way of a successful unification of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to merge: column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's already pretty obvious what the naming problem is. But just to demonstrate how to use _pandas_ to calculate differences, let's quickly take a look again at our DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Erl', 'Tyler'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in column names, using 'Erl' as the base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields__oSets__growthStage Zadoks',\n",
       " 'fields__oSets__oPoints__observations__a1__number EGA',\n",
       " 'fields__oSets__oPoints__observations__a2__number BCO',\n",
       " 'fields__oSets__oPoints__observations__a3__number Greenbug',\n",
       " 'fields__oSets__oPoints__observations__anum TotalAPhids',\n",
       " 'fields__oSets__oPoints__observations__eVnum Natural enemy totals'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(set.difference(*[set(sheet.columns) for sheet in sheets.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if we want to list the names of columns from *all* sheets that don't have a match (symmetrical difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = sorted(set.symmetric_difference(*[set(sheet.columns) for sheet in sheets.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we display the symmetric difference, let's pop it into a two column layout for _pandas_ to display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fields__oSets__growthStage</td>\n",
       "      <td>fields__oSets__growthStage Zadoks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fields__oSets__oPoints__observations__a1__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a1__number EGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fields__oSets__oPoints__observations__a2__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a2__number BCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fields__oSets__oPoints__observations__a3__number</td>\n",
       "      <td>fields__oSets__oPoints__observations__a3__number Greenbug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fields__oSets__oPoints__observations__anum</td>\n",
       "      <td>fields__oSets__oPoints__observations__anum TotalAPhids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fields__oSets__oPoints__observations__eVnum</td>\n",
       "      <td>fields__oSets__oPoints__observations__eVnum Natural enemy totals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "0  fields__oSets__growthStage                         \n",
       "1  fields__oSets__oPoints__observations__a1__number   \n",
       "2  fields__oSets__oPoints__observations__a2__number   \n",
       "3  fields__oSets__oPoints__observations__a3__number   \n",
       "4  fields__oSets__oPoints__observations__anum         \n",
       "5  fields__oSets__oPoints__observations__eVnum        \n",
       "\n",
       "                                                                  1  \n",
       "0  fields__oSets__growthStage Zadoks                                 \n",
       "1  fields__oSets__oPoints__observations__a1__number EGA              \n",
       "2  fields__oSets__oPoints__observations__a2__number BCO              \n",
       "3  fields__oSets__oPoints__observations__a3__number Greenbug         \n",
       "4  fields__oSets__oPoints__observations__anum TotalAPhids            \n",
       "5  fields__oSets__oPoints__observations__eVnum Natural enemy totals  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display entire column, even if cell data is long\n",
    "pandas.set_option('display.max_colwidth', 0)  # Zero means no limit\n",
    "\n",
    "# Show the differing column names side-by-side\n",
    "display(pandas.DataFrame([*zip(*[iter(column_list)] * 2)]))\n",
    "\n",
    "# Revert the setting that we changed\n",
    "pandas.reset_option('display.max_colwidth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate, we'll use the names from the first sheet, since it's more regular. Which sheet is the one to fix? Which sheet has `fields__oSets__growthStage Zadoks` instead of `fields__oSets__growthStage`? I believe \"Erl\" was our base for comparison initially, but let's make sure of what we're about to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Bad:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Erl'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a filtered dictionary, for later reference\n",
    "sheets_with_bad_column_names = {sheet_name: sheet for sheet_name, sheet in sheets.items() if 'fields__oSets__growthStage Zadoks' in sheet.columns}\n",
    "display(heading('Bad:'),\n",
    "        set(sheets_with_bad_column_names.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Good:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Tyler'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(heading('Good:'),\n",
    "        set(sheets.keys()) - set(sheets_with_bad_column_names.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, \"Tyler\" has the column names we prefer, \"Erl\" does not. Duly noted.\n",
    "\n",
    "There's now a `sheets_with_bad_column_names` variable we can use when we fix that. (It's only got one DataFrame, but it's still good practice to be ready for batch processing in case this code is reused in the future.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How shall we solve the name mismatch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our options:\n",
    "\n",
    "- rename the columns\n",
    "- try to merge the sheets in a way that ignores the column names of the bad sheet\n",
    "\n",
    "If we try to do a special merge, ignoring the column names, we have to worry about the _precise order_ of those columns instead of relying on the names. Since we'd have to spend time checking—and possibly rearranging—the column sequence, we might as well spend that time creating a _reusable_, documented solution for quick and painless name fixing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How (where) should we rename the columns/indices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibilities:\n",
    "\n",
    "- fix the spreadsheet document in Excel format, and move ahead as if this had never happened\n",
    "- keep the names in the file, but correct the names in memory once they become indices\n",
    "\n",
    "Since this notebook you're reading has already mentioned the problem, let's go ahead and solve it here. That way our notebook will detail the fix and how to use it in the future, if there are more Excel spreadsheets with similarly altered names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming indices (columns or rows) with _pandas_ functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ has a [`rename`] method which lets us apply a transform function to the indices named after our worksheet columns (or explicitly map each column through a dictionary).\n",
    "\n",
    "[`rename`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html\n",
    "\n",
    "Since the bad names merely have extra words tacked onto the end, let's just split the name and use the first \"word\". In Python, we get the first item of a sequence by using index zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word(string, word_separator=' '):\n",
    "    \"\"\" Split string into words (by space character), return first word. \"\"\"\n",
    "    return string.split(word_separator)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to apply this function to every Series in the DataFrame, through the _pandas_ rename function. For the sake of visualizing the changes, let's also report on changes in a dry run before using the _pandas_ rename function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Erl</h3><ol><li>fields__client__company</li><li>fields__client__name</li><li>fields__client__fname</li><li>fields__client__lname</li><li>fields__client__displayText</li><li>fields__name</li><li>fields__crop</li><li>fields__desc</li><li>fields__image</li><li>fields__date</li><li>fields__oSets__date</li><li>fields__oSets__dateCompare</li><li style='font-weight: bold'>fields__oSets__growthStage Zadoks &rarr; fields__oSets__growthStage</li><li>fields__oSets__desc</li><li>fields__oSets__obsName</li><li>fields__oSets__totalSets</li><li>fields__oSets__completeSets</li><li>fields__oSets__results</li><li>fields__oSets__oPoints__id</li><li>fields__oSets__oPoints__name</li><li>fields__oSets__oPoints__observations__id</li><li>fields__oSets__oPoints__observations__name</li><li>fields__oSets__oPoints__observations__enum</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__eVnum Natural enemy totals &rarr; fields__oSets__oPoints__observations__eVnum</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__anum TotalAPhids &rarr; fields__oSets__oPoints__observations__anum</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__a1__number EGA &rarr; fields__oSets__oPoints__observations__a1__number</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__a2__number BCO &rarr; fields__oSets__oPoints__observations__a2__number</li><li style='font-weight: bold'>fields__oSets__oPoints__observations__a3__number Greenbug &rarr; fields__oSets__oPoints__observations__a3__number</li><li>fields__oSets__oPoints__observations__disabled</li><li>fields__oSets__oPoints__observations__complete</li><li>fields__oSets__oPoints__observations__|</li><li>fields__oSets__oPoints__observations__|__number</li><li>fields__oSets__oPoints__location__coords__latitude</li><li>fields__oSets__oPoints__location__coords__longitude</li><li>fields__oSets__oPoints__location__coords__accuracy</li><li>fields__oSets__oPoints__location__coords__altitude</li><li>fields__oSets__oPoints__location__coords__heading</li><li>fields__oSets__oPoints__location__coords__speed</li><li>fields__oSets__oPoints__location__coords__altitudeAccuracy</li><li>fields__oSets__oPoints__location__timestamp</li><li>fields__oSets__totalA1</li><li>fields__oSets__totalA2</li><li>fields__oSets__totalA3</li><li>fields__oSets__totalA4</li><li>clients__company</li><li>clients__name</li><li>clients__fname</li><li>clients__lname</li><li>clients__displayText</li><li>observers</li></ol>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = []  # For the lines of the report which we'll display later.\n",
    "\n",
    "for sheet_name, sheet in sheets_with_bad_column_names.items():\n",
    "    report.append(make_heading(sheet_name, level=3))  # heading\n",
    "    report_lines = []  # the body of the report for each DataFrame\n",
    "    for column_name in sheet.columns:\n",
    "        after = first_word(column_name)\n",
    "        if after == column_name:\n",
    "            content = column_name\n",
    "            attributes = None\n",
    "        else:\n",
    "            content = f\"{column_name} &rarr; {after}\"  # old --> new\n",
    "            attributes = \"style='font-weight: bold'\"\n",
    "        report_lines.append(html_wrap(content, 'li', attributes))  # add an HTML list item\n",
    "    report.append(html_wrap(''.join(report_lines), 'ol')) # add an ordered list of items to the report\n",
    "    \n",
    "# join all the strings together and display as HTML\n",
    "display(HTML(''.join(report)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually change the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in sheets_with_bad_column_names.values():\n",
    "    sheet.rename(mapper=first_word, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, we know there's only one sheet, so the `for` loop isn't absolutely necessary, but it's still a good habit when dealing with reusable scripts that can work on batches of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of really long, repetitive column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ has a concept of [indexing hierarchically], which may help group columns together. However, I'm new to _pandas_ and I'm not new to Python. Furthermore, from what I've read, if we use a multi-level labelling system for grouping, we have to pay attention to which level we're operating on as we work with the spreadsheet as DataFrame. \n",
    "\n",
    "To avoid complications due to my own ignorance, let's use a nested dictionary in Python to accomplish the same thing without _pandas_. We can probably use the dictionary to help us add more indices to the DataFrame later, if we need.\n",
    "\n",
    "[indexing hierarchically]: https://pandas.pydata.org/pandas-docs/stable/advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested dictionaries, for a hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a regular dictionary in Python, let's use something called a [`defaultdict`], which will simplify the creation of our hierarchy. [`defaultdict`] is like a regular dictionary, except it doesn't complain if you try to access a key that doesn't exist yet—it just adds it.\n",
    "\n",
    "[`defaultdict`]: https://docs.python.org/3/library/collections.html#collections.defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method looks long but it's mostly comments for your benefit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def split_column_to_dict(sheet, column_name, column_dictionary=None, separator='__'):\n",
    "    \"\"\" Split the column names like \"fields__oSets__oPoints__observations\" into groupings of keys\n",
    "    so that related keys are easy to find, ie columns['fields']['oSets']['oPoints']['observations'].\n",
    "    This produces a tree of column name segments, with references to actual data at the ends.\"\"\"\n",
    "\n",
    "    # If a dictionary is not provided, make an empty one.\n",
    "    if column_dictionary is None:\n",
    "        def nested_dict():\n",
    "            \"\"\" This function will be called by defaultdict\n",
    "            whenever a non-existent key is used. \"\"\"\n",
    "            return defaultdict(nested_dict)\n",
    "        \n",
    "        column_dictionary = nested_dict()\n",
    "\n",
    "    # Set a pointer to the root of the tree, for starters.\n",
    "    pointer = column_dictionary\n",
    "    \n",
    "    # Now, walk through the segments in order from left to right,\n",
    "    # touching the tree for each one.\n",
    "    for segment in str(column_name).split(separator):\n",
    "        # Just update the pointer to the deeper location in the tree.\n",
    "        pointer = pointer[segment]\n",
    "    # Now that the loop is done, the pointer is pointing at the deepest\n",
    "    # level of the branch, which either already existed or it was created.\n",
    "    \n",
    "    # At the end of the branch, put the data.\n",
    "    # NOTE: To avoid naming conflicts with pandas magic attributes\n",
    "    # (such as \"number\"), the reference to data is in a node with a name that\n",
    "    # can't possibly be part of naming levels: the separator ('__') \n",
    "    pointer[separator] = sheet[column_name]  # the actual pandas \"column\"\n",
    "\n",
    "    # Since `pointer` was actually just pointing to parts of the column dictionary,\n",
    "    # the column dictionary has been filled out with nodes because of how defaultdict\n",
    "    # was setup with our `nested_dict` constructor.\n",
    "    return column_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, make a dictionary of column trees, grouped by sheet name.\n",
    "column_dictionary = {}\n",
    "separator = '__'\n",
    "for sheet_name, sheet in sheets.items():\n",
    "    # Build a new nested column dictionary for this sheet\n",
    "    new_dict = None\n",
    "    for column in sheet.columns:\n",
    "        new_dict = split_column_to_dict(sheet, column, new_dict, separator)\n",
    "    # Turn off the defaultdict behaviour of creating a key instead of throwinng an exception\n",
    "    new_dict.default_factory = None\n",
    "    column_dictionary[sheet_name] = new_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this worked, there should now be a list of sheets at the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Erl', 'Tyler'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there should be a list of the first segments of all the column names in that sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fields', 'clients', 'observers'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing deeper, more segments that share a common prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['client', 'name', 'crop', 'desc', 'image', 'date', 'oSets'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl']['fields'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['date', 'dateCompare', 'growthStage', 'desc', 'obsName', 'totalSets', 'completeSets', 'results', 'oPoints', 'totalA1', 'totalA2', 'totalA3', 'totalA4'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl']['fields']['oSets'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of each branch in the tree should be a '\\_\\_' key for the actual data. For example, the `date` of the set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl']['fields']['oSets']['date'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, if we want to skip over blanks as we scan down a column, _pandas_ has a [`dropna()`] method for that:\n",
    "\n",
    "[`dropna()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2017-08-02T13:12:09.542\n",
       "70     2017-08-09T09:25:11.710\n",
       "140    2017-08-09T10:06:25.480\n",
       "210    2017-08-09T11:21:01.555\n",
       "350    2017-08-09T11:37:20.862\n",
       "490    2017-08-22T15:42:05.751\n",
       "560    2017-08-17T11:12:02.820\n",
       "700    2017-08-17T13:06:30.183\n",
       "840    2017-08-22T16:02:50.682\n",
       "Name: fields__oSets__date, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl']['fields']['oSets']['date'][separator].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have enough information to find the beginning of chunks in the sheet by scanning for non-blank cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, the number of non-null (not empty) records in any given column was displayed when we called [`info()`] on the DataFrame. We can also get information like that from the column (which is a Series in _pandas_) by using [`describe()`] or [`count()`]:\n",
    "\n",
    "[`info()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\n",
    "[`describe()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.describe.html\n",
    "[`count()`]: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.count.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                           9\n",
       "unique                          9\n",
       "top       2017-08-02T13:12:09.542\n",
       "freq                            1\n",
       "Name: fields__oSets__date, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl']['fields']['oSets']['date'][separator].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions, for browsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we start actually reading groups of columns based on which type of chunk we're reading from, we'll have to start typing lists of column names for each section.\n",
    "\n",
    "It's a bit of extra work to pay attention to whether a given node in the hierarchy is holding a reference to a data Series (column) or whether it's only an intermediate step on the way to the end of the branch.\n",
    "\n",
    "To save time and mental energy, we can filter columns by whether they have data or not, if we make some simple filter functions. For detecting data that we've placed in the hierarchy of columns, we can look for the special key that we chose earlier (the separator, which is two underscore characters `__`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_data(node):\n",
    "    \"\"\" Filter children that have data. We know a child item has data\n",
    "    if it has a key that's the just the separator string. \"\"\"\n",
    "    return {parent_key: child for parent_key, child in node.items()\n",
    "            if separator in child.keys()}\n",
    "\n",
    "\n",
    "def has_children(node):\n",
    "    \"\"\" Filter children that have children. We know an item has children\n",
    "    if it has at least one key that isn't just the separator string, the\n",
    "    special key for data references. \"\"\"\n",
    "    return {parent_key: child for parent_key, child in node.items()\n",
    "            if len([key for key in child.keys() if key != separator]) >= 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>children with children:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['a1', 'a2', 'a3', '|'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_node = column_dictionary[sheet_name]['fields']['oSets']['oPoints']['observations']\n",
    "display(heading('children with children:'),\n",
    "        has_children(example_node).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>children with data:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'name', 'enum', 'eVnum', 'anum', 'disabled', 'complete', '|'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(heading('children with data:'),\n",
    "        has_data(example_node).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>children with children & data:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'|'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set of keys for nodes that that have children but also data:\n",
    "display(heading('children with children & data:'),\n",
    "        set(has_children(example_node).keys()) & set(has_data(example_node).keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal thought:\n",
    "\n",
    "I have to wonder why the developers of the app that output this data chose to use an unpronounceable column name, and put something important there.\n",
    "\n",
    "Regardless, we can effortlessly handle it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated elements: fields, sets, points, observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the columns containing data about observation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Erl:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fields__oSets__date</th>\n",
       "      <th>fields__oSets__dateCompare</th>\n",
       "      <th>fields__oSets__growthStage</th>\n",
       "      <th>fields__oSets__desc</th>\n",
       "      <th>fields__oSets__obsName</th>\n",
       "      <th>fields__oSets__totalSets</th>\n",
       "      <th>fields__oSets__completeSets</th>\n",
       "      <th>fields__oSets__results</th>\n",
       "      <th>fields__oSets__totalA1</th>\n",
       "      <th>fields__oSets__totalA2</th>\n",
       "      <th>fields__oSets__totalA3</th>\n",
       "      <th>fields__oSets__totalA4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-02T13:12:09.542</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2017-08-09T09:25:11.710</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2017-08-09T10:06:25.480</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fields__oSets__date fields__oSets__dateCompare  \\\n",
       "0    2017-08-02T13:12:09.542                 2017-08-02   \n",
       "70   2017-08-09T09:25:11.710                 2017-08-09   \n",
       "140  2017-08-09T10:06:25.480                 2017-08-09   \n",
       "\n",
       "     fields__oSets__growthStage  fields__oSets__desc fields__oSets__obsName  \\\n",
       "0                           7.0                  NaN                  Tyler   \n",
       "70                          8.0                  NaN                  Tyler   \n",
       "140                         7.0                  NaN                  Tyler   \n",
       "\n",
       "     fields__oSets__totalSets  fields__oSets__completeSets  \\\n",
       "0                         1.0                          0.0   \n",
       "70                        1.0                          1.0   \n",
       "140                       1.0                          1.0   \n",
       "\n",
       "    fields__oSets__results  fields__oSets__totalA1  fields__oSets__totalA2  \\\n",
       "0                      NaN                     NaN                     NaN   \n",
       "70               RESULTS.5                   164.0                     0.0   \n",
       "140              RESULTS.5                    66.0                     0.0   \n",
       "\n",
       "     fields__oSets__totalA3  fields__oSets__totalA4  \n",
       "0                       NaN                     NaN  \n",
       "70                      0.0                     0.0  \n",
       "140                     0.0                     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Tyler:</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fields__oSets__date</th>\n",
       "      <th>fields__oSets__dateCompare</th>\n",
       "      <th>fields__oSets__growthStage</th>\n",
       "      <th>fields__oSets__desc</th>\n",
       "      <th>fields__oSets__obsName</th>\n",
       "      <th>fields__oSets__totalSets</th>\n",
       "      <th>fields__oSets__completeSets</th>\n",
       "      <th>fields__oSets__results</th>\n",
       "      <th>fields__oSets__totalA1</th>\n",
       "      <th>fields__oSets__totalA2</th>\n",
       "      <th>fields__oSets__totalA3</th>\n",
       "      <th>fields__oSets__totalA4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-14T12:31:24.194</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2017-07-18T10:31:22.263</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2017-07-28T13:05:44.673</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mikki</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RESULTS.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fields__oSets__date fields__oSets__dateCompare  \\\n",
       "0    2017-07-14T12:31:24.194                 2017-07-14   \n",
       "70   2017-07-18T10:31:22.263                 2017-07-18   \n",
       "140  2017-07-28T13:05:44.673                 2017-07-28   \n",
       "\n",
       "     fields__oSets__growthStage  fields__oSets__desc fields__oSets__obsName  \\\n",
       "0                           6.0                  NaN                  Tyler   \n",
       "70                          6.0                  NaN                  Tyler   \n",
       "140                         8.0                  NaN                  Mikki   \n",
       "\n",
       "     fields__oSets__totalSets  fields__oSets__completeSets  \\\n",
       "0                         1.0                          0.0   \n",
       "70                        1.0                          1.0   \n",
       "140                       1.0                          1.0   \n",
       "\n",
       "    fields__oSets__results  fields__oSets__totalA1  fields__oSets__totalA2  \\\n",
       "0                      NaN                     NaN                     NaN   \n",
       "70               RESULTS.5                     8.0                     0.0   \n",
       "140              RESULTS.5                    37.0                     0.0   \n",
       "\n",
       "     fields__oSets__totalA3  fields__oSets__totalA4  \n",
       "0                       NaN                     NaN  \n",
       "70                      0.0                     0.0  \n",
       "140                     0.0                     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sheet_name, column_tree in column_dictionary.items():\n",
    "    node = column_tree['fields']['oSets']\n",
    "    date_column = node['date'][separator]\n",
    "    columns = [child[separator].name for parent_key, child in has_data(node).items()]\n",
    "    display(heading(f\"{sheet_name}:\"),\n",
    "            sheets[sheet_name].loc[date_column.isna() != True, columns].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask _pandas_ to drop all the blanks and see which rows remain for the column here (`fields__oSets__date`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 70, 140, 210, 350, 490, 560, 700, 840], dtype='int64')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Erl']['fields']['oSets']['date'][separator].dropna().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many 'oSets' sections of the file are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_)  # Based on the length of that list we just output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to know. What about the other file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dictionary['Tyler']['fields']['oSets']['date'][separator].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ + __  # add the last two numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 54 sets of observations we'll be processing.\n",
    "\n",
    "How many observation _points_ will we be processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oPoints'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointer = column_dictionary['Tyler']['fields']['oSets']\n",
    "has_children(pointer).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
